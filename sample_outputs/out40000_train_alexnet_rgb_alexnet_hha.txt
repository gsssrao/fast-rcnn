added /data/gpuuser1/fast-rcnn/caffe-fast-rcnn/python
added /data/gpuuser1/fast-rcnn/lib
added /data/gpuuser1/fast-rcnn/python_utils
added /data/gpuuser1/fast-rcnn/.
Called with args:
Namespace(caffemodel='output/training_demo/alexnet_rgb_alexnet_hha/nyud2_images+hha_2015_trainval_exp/fast_rcnn_iter_exp_40000.caffemodel', cfg_file='output/training_demo/alexnet_rgb_alexnet_hha/config.prototxt.images+hha', comp_mode=False, gpu_id=0, imdb_name='nyud2_images+hha_2015_test', prototxt='output/training_demo/alexnet_rgb_alexnet_hha/test.prototxt.images+hha', wait=True)
Using config:
{'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'training_demo/alexnet_rgb_alexnet_hha',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/data/gpuuser1/fast-rcnn',
 'TEST': {'BBOX_REG': True,
          'DET_SALT': '',
          'EVAL_SALT': '',
          'MAX_PER_IMAGE': 100,
          'MAX_PER_SET_F': 40,
          'MAX_SIZE': 2000,
          'NMS': 0.3,
          'SCALES': [688],
          'SVM': False},
 'TRAIN': {'BATCH_SIZE': 128,
           'BBOX_PRED_PARAM_NAMES': ['bbox_pred', 'da_bbox_pred'],
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 2000,
           'SCALES': [688],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False}}
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1015 00:07:32.206977 19737 net.cpp:42] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
input: "data_1"
input: "rois"
state {
  phase: TEST
}
input_shape {
  dim: 1
  dim: 3
  dim: 227
  dim: 227
}
input_shape {
  dim: 1
  dim: 3
  dim: 227
  dim: 227
}
input_shape {
  dim: 1
  dim: 5
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 5
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 6
    pooled_w: 6
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "da_conv1"
  type: "Convolution"
  bottom: "data_1"
  top: "da_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 7
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "da_relu1"
  type: "ReLU"
  bottom: "da_conv1"
  top: "da_conv1"
}
layer {
  name: "da_pool1"
  type: "Pooling"
  bottom: "da_conv1"
  top: "da_pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "da_norm1"
  type: "LRN"
  bottom: "da_pool1"
  top: "da_norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "da_conv2"
  type: "Convolution"
  bottom: "da_norm1"
  top: "da_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "da_relu2"
  type: "ReLU"
  bottom: "da_conv2"
  top: "da_conv2"
}
layer {
  name: "da_pool2"
  type: "Pooling"
  bottom: "da_conv2"
  top: "da_pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "da_norm2"
  type: "LRN"
  bottom: "da_pool2"
  top: "da_norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "da_conv3"
  type: "Convolution"
  bottom: "da_norm2"
  top: "da_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "da_relu3"
  type: "ReLU"
  bottom: "da_conv3"
  top: "da_conv3"
}
layer {
  name: "da_conv4"
  type: "Convolution"
  bottom: "da_conv3"
  top: "da_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "da_relu4"
  type: "ReLU"
  bottom: "da_conv4"
  top: "da_conv4"
}
layer {
  name: "da_conv5"
  type: "Convolution"
  bottom: "da_conv4"
  top: "da_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "da_relu5"
  type: "ReLU"
  bottom: "da_conv5"
  top: "da_conv5"
}
layer {
  name: "da_roi_pool5"
  type: "ROIPooling"
  bottom: "da_conv5"
  bottom: "rois"
  top: "da_pool5"
  roi_pooling_param {
    pooled_h: 6
    pooled_w: 6
    spatial_scale: 0.0625
  }
}
layer {
  name: "da_fc6"
  type: "InnerProduct"
  bottom: "da_pool5"
  top: "da_fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "da_relu6"
  type: "ReLU"
  bottom: "da_fc6"
  top: "da_fc6"
}
layer {
  name: "da_drop6"
  type: "Dropout"
  bottom: "da_fc6"
  top: "da_fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "da_fc7"
  type: "InnerProduct"
  bottom: "da_fc6"
  top: "da_fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "da_relu7"
  type: "ReLU"
  bottom: "da_fc7"
  top: "da_fc7"
}
layer {
  name: "da_drop7"
  type: "Dropout"
  bottom: "da_fc7"
  top: "da_fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 20
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "da_cls_score"
  type: "InnerProduct"
  bottom: "da_fc7"
  top: "cls_score_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 20
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 80
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "da_bbox_pred"
  type: "InnerProduct"
  bottom: "da_fc7"
  top: "bbox_pred_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 80
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "sum"
  type: "Eltwise"
  bottom: "bbox_pred_0"
  bottom: "bbox_pred_1"
  top: "bbox_pred"
  eltwise_param {
    operation: SUM
    coeff: 0.5
    coeff: 0.5
  }
}
layer {
  name: "sum"
  type: "Eltwise"
  bottom: "cls_score_0"
  bottom: "cls_score_1"
  top: "cls_score"
  eltwise_param {
    operation: SUM
    coeff: 0.5
    coeff: 0.5
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}
I1015 00:07:32.207239 19737 net.cpp:340] Input 0 -> data
I1015 00:07:32.207270 19737 net.cpp:340] Input 1 -> data_1
I1015 00:07:32.207280 19737 net.cpp:340] Input 2 -> rois
I1015 00:07:32.207303 19737 layer_factory.hpp:74] Creating layer rois_input_2_split
I1015 00:07:32.207317 19737 net.cpp:84] Creating Layer rois_input_2_split
I1015 00:07:32.207324 19737 net.cpp:380] rois_input_2_split <- rois
I1015 00:07:32.207334 19737 net.cpp:338] rois_input_2_split -> rois_input_2_split_0
I1015 00:07:32.207345 19737 net.cpp:338] rois_input_2_split -> rois_input_2_split_1
I1015 00:07:32.207355 19737 net.cpp:113] Setting up rois_input_2_split
I1015 00:07:32.207372 19737 net.cpp:120] Top shape: 1 5 (5)
I1015 00:07:32.207381 19737 net.cpp:120] Top shape: 1 5 (5)
I1015 00:07:32.207388 19737 layer_factory.hpp:74] Creating layer conv1
I1015 00:07:32.207401 19737 net.cpp:84] Creating Layer conv1
I1015 00:07:32.207407 19737 net.cpp:380] conv1 <- data
I1015 00:07:32.207417 19737 net.cpp:338] conv1 -> conv1
I1015 00:07:32.207427 19737 net.cpp:113] Setting up conv1
I1015 00:07:32.266036 19737 net.cpp:120] Top shape: 1 96 57 57 (311904)
I1015 00:07:32.266077 19737 layer_factory.hpp:74] Creating layer relu1
I1015 00:07:32.266094 19737 net.cpp:84] Creating Layer relu1
I1015 00:07:32.266103 19737 net.cpp:380] relu1 <- conv1
I1015 00:07:32.266113 19737 net.cpp:327] relu1 -> conv1 (in-place)
I1015 00:07:32.266124 19737 net.cpp:113] Setting up relu1
I1015 00:07:32.266188 19737 net.cpp:120] Top shape: 1 96 57 57 (311904)
I1015 00:07:32.266201 19737 layer_factory.hpp:74] Creating layer pool1
I1015 00:07:32.266209 19737 layer_factory.cpp:56] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I1015 00:07:32.266218 19737 net.cpp:84] Creating Layer pool1
I1015 00:07:32.266225 19737 net.cpp:380] pool1 <- conv1
I1015 00:07:32.266234 19737 net.cpp:338] pool1 -> pool1
I1015 00:07:32.266244 19737 net.cpp:113] Setting up pool1
I1015 00:07:32.266260 19737 net.cpp:120] Top shape: 1 96 29 29 (80736)
I1015 00:07:32.266268 19737 layer_factory.hpp:74] Creating layer norm1
I1015 00:07:32.266281 19737 net.cpp:84] Creating Layer norm1
I1015 00:07:32.266289 19737 net.cpp:380] norm1 <- pool1
I1015 00:07:32.266297 19737 net.cpp:338] norm1 -> norm1
I1015 00:07:32.266307 19737 net.cpp:113] Setting up norm1
I1015 00:07:32.266319 19737 net.cpp:120] Top shape: 1 96 29 29 (80736)
I1015 00:07:32.266329 19737 layer_factory.hpp:74] Creating layer conv2
I1015 00:07:32.266340 19737 net.cpp:84] Creating Layer conv2
I1015 00:07:32.266345 19737 net.cpp:380] conv2 <- norm1
I1015 00:07:32.266355 19737 net.cpp:338] conv2 -> conv2
I1015 00:07:32.266366 19737 net.cpp:113] Setting up conv2
I1015 00:07:32.267249 19737 net.cpp:120] Top shape: 1 256 29 29 (215296)
I1015 00:07:32.267271 19737 layer_factory.hpp:74] Creating layer relu2
I1015 00:07:32.267283 19737 net.cpp:84] Creating Layer relu2
I1015 00:07:32.267290 19737 net.cpp:380] relu2 <- conv2
I1015 00:07:32.267299 19737 net.cpp:327] relu2 -> conv2 (in-place)
I1015 00:07:32.267308 19737 net.cpp:113] Setting up relu2
I1015 00:07:32.267364 19737 net.cpp:120] Top shape: 1 256 29 29 (215296)
I1015 00:07:32.267375 19737 layer_factory.hpp:74] Creating layer pool2
I1015 00:07:32.267382 19737 layer_factory.cpp:56] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I1015 00:07:32.267391 19737 net.cpp:84] Creating Layer pool2
I1015 00:07:32.267397 19737 net.cpp:380] pool2 <- conv2
I1015 00:07:32.267406 19737 net.cpp:338] pool2 -> pool2
I1015 00:07:32.267416 19737 net.cpp:113] Setting up pool2
I1015 00:07:32.267427 19737 net.cpp:120] Top shape: 1 256 15 15 (57600)
I1015 00:07:32.267436 19737 layer_factory.hpp:74] Creating layer norm2
I1015 00:07:32.267446 19737 net.cpp:84] Creating Layer norm2
I1015 00:07:32.267453 19737 net.cpp:380] norm2 <- pool2
I1015 00:07:32.267462 19737 net.cpp:338] norm2 -> norm2
I1015 00:07:32.267470 19737 net.cpp:113] Setting up norm2
I1015 00:07:32.267480 19737 net.cpp:120] Top shape: 1 256 15 15 (57600)
I1015 00:07:32.267488 19737 layer_factory.hpp:74] Creating layer conv3
I1015 00:07:32.267496 19737 net.cpp:84] Creating Layer conv3
I1015 00:07:32.267503 19737 net.cpp:380] conv3 <- norm2
I1015 00:07:32.267511 19737 net.cpp:338] conv3 -> conv3
I1015 00:07:32.267520 19737 net.cpp:113] Setting up conv3
I1015 00:07:32.269395 19737 net.cpp:120] Top shape: 1 384 15 15 (86400)
I1015 00:07:32.269423 19737 layer_factory.hpp:74] Creating layer relu3
I1015 00:07:32.269433 19737 net.cpp:84] Creating Layer relu3
I1015 00:07:32.269441 19737 net.cpp:380] relu3 <- conv3
I1015 00:07:32.269450 19737 net.cpp:327] relu3 -> conv3 (in-place)
I1015 00:07:32.269459 19737 net.cpp:113] Setting up relu3
I1015 00:07:32.269515 19737 net.cpp:120] Top shape: 1 384 15 15 (86400)
I1015 00:07:32.269526 19737 layer_factory.hpp:74] Creating layer conv4
I1015 00:07:32.269537 19737 net.cpp:84] Creating Layer conv4
I1015 00:07:32.269543 19737 net.cpp:380] conv4 <- conv3
I1015 00:07:32.269553 19737 net.cpp:338] conv4 -> conv4
I1015 00:07:32.269563 19737 net.cpp:113] Setting up conv4
I1015 00:07:32.271605 19737 net.cpp:120] Top shape: 1 384 15 15 (86400)
I1015 00:07:32.271626 19737 layer_factory.hpp:74] Creating layer relu4
I1015 00:07:32.271637 19737 net.cpp:84] Creating Layer relu4
I1015 00:07:32.271644 19737 net.cpp:380] relu4 <- conv4
I1015 00:07:32.271653 19737 net.cpp:327] relu4 -> conv4 (in-place)
I1015 00:07:32.271663 19737 net.cpp:113] Setting up relu4
I1015 00:07:32.271853 19737 net.cpp:120] Top shape: 1 384 15 15 (86400)
I1015 00:07:32.271868 19737 layer_factory.hpp:74] Creating layer conv5
I1015 00:07:32.271879 19737 net.cpp:84] Creating Layer conv5
I1015 00:07:32.271886 19737 net.cpp:380] conv5 <- conv4
I1015 00:07:32.271896 19737 net.cpp:338] conv5 -> conv5
I1015 00:07:32.271906 19737 net.cpp:113] Setting up conv5
I1015 00:07:32.273511 19737 net.cpp:120] Top shape: 1 256 15 15 (57600)
I1015 00:07:32.273536 19737 layer_factory.hpp:74] Creating layer relu5
I1015 00:07:32.273550 19737 net.cpp:84] Creating Layer relu5
I1015 00:07:32.273557 19737 net.cpp:380] relu5 <- conv5
I1015 00:07:32.273566 19737 net.cpp:327] relu5 -> conv5 (in-place)
I1015 00:07:32.273576 19737 net.cpp:113] Setting up relu5
I1015 00:07:32.273641 19737 net.cpp:120] Top shape: 1 256 15 15 (57600)
I1015 00:07:32.273653 19737 layer_factory.hpp:74] Creating layer roi_pool5
I1015 00:07:32.273669 19737 net.cpp:84] Creating Layer roi_pool5
I1015 00:07:32.273679 19737 net.cpp:380] roi_pool5 <- conv5
I1015 00:07:32.273686 19737 net.cpp:380] roi_pool5 <- rois_input_2_split_0
I1015 00:07:32.273695 19737 net.cpp:338] roi_pool5 -> pool5
I1015 00:07:32.273705 19737 net.cpp:113] Setting up roi_pool5
I1015 00:07:32.273715 19737 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1015 00:07:32.273741 19737 net.cpp:120] Top shape: 1 256 6 6 (9216)
I1015 00:07:32.273748 19737 layer_factory.hpp:74] Creating layer fc6
I1015 00:07:32.273763 19737 net.cpp:84] Creating Layer fc6
I1015 00:07:32.273772 19737 net.cpp:380] fc6 <- pool5
I1015 00:07:32.273782 19737 net.cpp:338] fc6 -> fc6
I1015 00:07:32.273792 19737 net.cpp:113] Setting up fc6
I1015 00:07:32.329083 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.329125 19737 layer_factory.hpp:74] Creating layer relu6
I1015 00:07:32.329141 19737 net.cpp:84] Creating Layer relu6
I1015 00:07:32.329149 19737 net.cpp:380] relu6 <- fc6
I1015 00:07:32.329160 19737 net.cpp:327] relu6 -> fc6 (in-place)
I1015 00:07:32.329174 19737 net.cpp:113] Setting up relu6
I1015 00:07:32.329273 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.329285 19737 layer_factory.hpp:74] Creating layer drop6
I1015 00:07:32.329300 19737 net.cpp:84] Creating Layer drop6
I1015 00:07:32.329308 19737 net.cpp:380] drop6 <- fc6
I1015 00:07:32.329320 19737 net.cpp:327] drop6 -> fc6 (in-place)
I1015 00:07:32.329334 19737 net.cpp:113] Setting up drop6
I1015 00:07:32.329344 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.329354 19737 layer_factory.hpp:74] Creating layer fc7
I1015 00:07:32.329365 19737 net.cpp:84] Creating Layer fc7
I1015 00:07:32.329370 19737 net.cpp:380] fc7 <- fc6
I1015 00:07:32.329381 19737 net.cpp:338] fc7 -> fc7
I1015 00:07:32.329396 19737 net.cpp:113] Setting up fc7
I1015 00:07:32.354331 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.354377 19737 layer_factory.hpp:74] Creating layer relu7
I1015 00:07:32.354400 19737 net.cpp:84] Creating Layer relu7
I1015 00:07:32.354409 19737 net.cpp:380] relu7 <- fc7
I1015 00:07:32.354420 19737 net.cpp:327] relu7 -> fc7 (in-place)
I1015 00:07:32.354432 19737 net.cpp:113] Setting up relu7
I1015 00:07:32.354743 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.354758 19737 layer_factory.hpp:74] Creating layer drop7
I1015 00:07:32.354769 19737 net.cpp:84] Creating Layer drop7
I1015 00:07:32.354776 19737 net.cpp:380] drop7 <- fc7
I1015 00:07:32.354785 19737 net.cpp:327] drop7 -> fc7 (in-place)
I1015 00:07:32.354795 19737 net.cpp:113] Setting up drop7
I1015 00:07:32.354805 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.354812 19737 layer_factory.hpp:74] Creating layer fc7_drop7_0_split
I1015 00:07:32.354825 19737 net.cpp:84] Creating Layer fc7_drop7_0_split
I1015 00:07:32.354831 19737 net.cpp:380] fc7_drop7_0_split <- fc7
I1015 00:07:32.354840 19737 net.cpp:338] fc7_drop7_0_split -> fc7_drop7_0_split_0
I1015 00:07:32.354851 19737 net.cpp:338] fc7_drop7_0_split -> fc7_drop7_0_split_1
I1015 00:07:32.354861 19737 net.cpp:113] Setting up fc7_drop7_0_split
I1015 00:07:32.354872 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.354881 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:32.354887 19737 layer_factory.hpp:74] Creating layer da_conv1
I1015 00:07:32.354898 19737 net.cpp:84] Creating Layer da_conv1
I1015 00:07:32.354909 19737 net.cpp:380] da_conv1 <- data_1
I1015 00:07:32.354921 19737 net.cpp:338] da_conv1 -> da_conv1
I1015 00:07:32.354935 19737 net.cpp:113] Setting up da_conv1
I1015 00:07:32.356912 19737 net.cpp:120] Top shape: 1 96 58 58 (322944)
I1015 00:07:32.356932 19737 layer_factory.hpp:74] Creating layer da_relu1
I1015 00:07:32.356947 19737 net.cpp:84] Creating Layer da_relu1
I1015 00:07:32.356956 19737 net.cpp:380] da_relu1 <- da_conv1
I1015 00:07:32.356966 19737 net.cpp:327] da_relu1 -> da_conv1 (in-place)
I1015 00:07:32.356976 19737 net.cpp:113] Setting up da_relu1
I1015 00:07:32.357040 19737 net.cpp:120] Top shape: 1 96 58 58 (322944)
I1015 00:07:32.357053 19737 layer_factory.hpp:74] Creating layer da_pool1
I1015 00:07:32.357064 19737 net.cpp:84] Creating Layer da_pool1
I1015 00:07:32.357070 19737 net.cpp:380] da_pool1 <- da_conv1
I1015 00:07:32.357079 19737 net.cpp:338] da_pool1 -> da_pool1
I1015 00:07:32.357089 19737 net.cpp:113] Setting up da_pool1
I1015 00:07:32.357164 19737 net.cpp:120] Top shape: 1 96 29 29 (80736)
I1015 00:07:32.357177 19737 layer_factory.hpp:74] Creating layer da_norm1
I1015 00:07:32.357187 19737 net.cpp:84] Creating Layer da_norm1
I1015 00:07:32.357194 19737 net.cpp:380] da_norm1 <- da_pool1
I1015 00:07:32.357203 19737 net.cpp:338] da_norm1 -> da_norm1
I1015 00:07:32.357213 19737 net.cpp:113] Setting up da_norm1
I1015 00:07:32.357223 19737 net.cpp:120] Top shape: 1 96 29 29 (80736)
I1015 00:07:32.357229 19737 layer_factory.hpp:74] Creating layer da_conv2
I1015 00:07:32.357242 19737 net.cpp:84] Creating Layer da_conv2
I1015 00:07:32.357251 19737 net.cpp:380] da_conv2 <- da_norm1
I1015 00:07:32.357260 19737 net.cpp:338] da_conv2 -> da_conv2
I1015 00:07:32.357270 19737 net.cpp:113] Setting up da_conv2
I1015 00:07:32.368950 19737 net.cpp:120] Top shape: 1 256 29 29 (215296)
I1015 00:07:32.368978 19737 layer_factory.hpp:74] Creating layer da_relu2
I1015 00:07:32.368989 19737 net.cpp:84] Creating Layer da_relu2
I1015 00:07:32.368996 19737 net.cpp:380] da_relu2 <- da_conv2
I1015 00:07:32.369007 19737 net.cpp:327] da_relu2 -> da_conv2 (in-place)
I1015 00:07:32.369016 19737 net.cpp:113] Setting up da_relu2
I1015 00:07:32.369086 19737 net.cpp:120] Top shape: 1 256 29 29 (215296)
I1015 00:07:32.369098 19737 layer_factory.hpp:74] Creating layer da_pool2
I1015 00:07:32.369108 19737 net.cpp:84] Creating Layer da_pool2
I1015 00:07:32.369115 19737 net.cpp:380] da_pool2 <- da_conv2
I1015 00:07:32.369124 19737 net.cpp:338] da_pool2 -> da_pool2
I1015 00:07:32.369133 19737 net.cpp:113] Setting up da_pool2
I1015 00:07:32.369338 19737 net.cpp:120] Top shape: 1 256 14 14 (50176)
I1015 00:07:32.369354 19737 layer_factory.hpp:74] Creating layer da_norm2
I1015 00:07:32.369365 19737 net.cpp:84] Creating Layer da_norm2
I1015 00:07:32.369374 19737 net.cpp:380] da_norm2 <- da_pool2
I1015 00:07:32.369382 19737 net.cpp:338] da_norm2 -> da_norm2
I1015 00:07:32.369392 19737 net.cpp:113] Setting up da_norm2
I1015 00:07:32.369405 19737 net.cpp:120] Top shape: 1 256 14 14 (50176)
I1015 00:07:32.369412 19737 layer_factory.hpp:74] Creating layer da_conv3
I1015 00:07:32.369422 19737 net.cpp:84] Creating Layer da_conv3
I1015 00:07:32.369428 19737 net.cpp:380] da_conv3 <- da_norm2
I1015 00:07:32.369442 19737 net.cpp:338] da_conv3 -> da_conv3
I1015 00:07:32.369455 19737 net.cpp:113] Setting up da_conv3
I1015 00:07:32.401079 19737 net.cpp:120] Top shape: 1 384 14 14 (75264)
I1015 00:07:32.401101 19737 layer_factory.hpp:74] Creating layer da_relu3
I1015 00:07:32.401118 19737 net.cpp:84] Creating Layer da_relu3
I1015 00:07:32.401124 19737 net.cpp:380] da_relu3 <- da_conv3
I1015 00:07:32.401134 19737 net.cpp:327] da_relu3 -> da_conv3 (in-place)
I1015 00:07:32.401142 19737 net.cpp:113] Setting up da_relu3
I1015 00:07:32.401211 19737 net.cpp:120] Top shape: 1 384 14 14 (75264)
I1015 00:07:32.401223 19737 layer_factory.hpp:74] Creating layer da_conv4
I1015 00:07:32.401237 19737 net.cpp:84] Creating Layer da_conv4
I1015 00:07:32.401243 19737 net.cpp:380] da_conv4 <- da_conv3
I1015 00:07:32.401255 19737 net.cpp:338] da_conv4 -> da_conv4
I1015 00:07:32.401268 19737 net.cpp:113] Setting up da_conv4
I1015 00:07:32.425730 19737 net.cpp:120] Top shape: 1 384 14 14 (75264)
I1015 00:07:32.425750 19737 layer_factory.hpp:74] Creating layer da_relu4
I1015 00:07:32.425760 19737 net.cpp:84] Creating Layer da_relu4
I1015 00:07:32.425767 19737 net.cpp:380] da_relu4 <- da_conv4
I1015 00:07:32.425779 19737 net.cpp:327] da_relu4 -> da_conv4 (in-place)
I1015 00:07:32.425789 19737 net.cpp:113] Setting up da_relu4
I1015 00:07:32.425858 19737 net.cpp:120] Top shape: 1 384 14 14 (75264)
I1015 00:07:32.425869 19737 layer_factory.hpp:74] Creating layer da_conv5
I1015 00:07:32.425884 19737 net.cpp:84] Creating Layer da_conv5
I1015 00:07:32.425890 19737 net.cpp:380] da_conv5 <- da_conv4
I1015 00:07:32.425899 19737 net.cpp:338] da_conv5 -> da_conv5
I1015 00:07:32.425910 19737 net.cpp:113] Setting up da_conv5
I1015 00:07:32.442448 19737 net.cpp:120] Top shape: 1 256 14 14 (50176)
I1015 00:07:32.442468 19737 layer_factory.hpp:74] Creating layer da_relu5
I1015 00:07:32.442478 19737 net.cpp:84] Creating Layer da_relu5
I1015 00:07:32.442486 19737 net.cpp:380] da_relu5 <- da_conv5
I1015 00:07:32.442494 19737 net.cpp:327] da_relu5 -> da_conv5 (in-place)
I1015 00:07:32.442503 19737 net.cpp:113] Setting up da_relu5
I1015 00:07:32.442569 19737 net.cpp:120] Top shape: 1 256 14 14 (50176)
I1015 00:07:32.442580 19737 layer_factory.hpp:74] Creating layer da_roi_pool5
I1015 00:07:32.442591 19737 net.cpp:84] Creating Layer da_roi_pool5
I1015 00:07:32.442600 19737 net.cpp:380] da_roi_pool5 <- da_conv5
I1015 00:07:32.442608 19737 net.cpp:380] da_roi_pool5 <- rois_input_2_split_1
I1015 00:07:32.442618 19737 net.cpp:338] da_roi_pool5 -> da_pool5
I1015 00:07:32.442628 19737 net.cpp:113] Setting up da_roi_pool5
I1015 00:07:32.442638 19737 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1015 00:07:32.442661 19737 net.cpp:120] Top shape: 1 256 6 6 (9216)
I1015 00:07:32.442667 19737 layer_factory.hpp:74] Creating layer da_fc6
I1015 00:07:32.442677 19737 net.cpp:84] Creating Layer da_fc6
I1015 00:07:32.442687 19737 net.cpp:380] da_fc6 <- da_pool5
I1015 00:07:32.442703 19737 net.cpp:338] da_fc6 -> da_fc6
I1015 00:07:32.442715 19737 net.cpp:113] Setting up da_fc6
I1015 00:07:33.766160 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:33.766203 19737 layer_factory.hpp:74] Creating layer da_relu6
I1015 00:07:33.766218 19737 net.cpp:84] Creating Layer da_relu6
I1015 00:07:33.766227 19737 net.cpp:380] da_relu6 <- da_fc6
I1015 00:07:33.766238 19737 net.cpp:327] da_relu6 -> da_fc6 (in-place)
I1015 00:07:33.766249 19737 net.cpp:113] Setting up da_relu6
I1015 00:07:33.766558 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:33.766574 19737 layer_factory.hpp:74] Creating layer da_drop6
I1015 00:07:33.766585 19737 net.cpp:84] Creating Layer da_drop6
I1015 00:07:33.766592 19737 net.cpp:380] da_drop6 <- da_fc6
I1015 00:07:33.766603 19737 net.cpp:327] da_drop6 -> da_fc6 (in-place)
I1015 00:07:33.766613 19737 net.cpp:113] Setting up da_drop6
I1015 00:07:33.766628 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:33.766638 19737 layer_factory.hpp:74] Creating layer da_fc7
I1015 00:07:33.766649 19737 net.cpp:84] Creating Layer da_fc7
I1015 00:07:33.766656 19737 net.cpp:380] da_fc7 <- da_fc6
I1015 00:07:33.766669 19737 net.cpp:338] da_fc7 -> da_fc7
I1015 00:07:33.766682 19737 net.cpp:113] Setting up da_fc7
I1015 00:07:34.355010 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:34.355051 19737 layer_factory.hpp:74] Creating layer da_relu7
I1015 00:07:34.355067 19737 net.cpp:84] Creating Layer da_relu7
I1015 00:07:34.355077 19737 net.cpp:380] da_relu7 <- da_fc7
I1015 00:07:34.355088 19737 net.cpp:327] da_relu7 -> da_fc7 (in-place)
I1015 00:07:34.355099 19737 net.cpp:113] Setting up da_relu7
I1015 00:07:34.355253 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:34.355267 19737 layer_factory.hpp:74] Creating layer da_drop7
I1015 00:07:34.355279 19737 net.cpp:84] Creating Layer da_drop7
I1015 00:07:34.355286 19737 net.cpp:380] da_drop7 <- da_fc7
I1015 00:07:34.355294 19737 net.cpp:327] da_drop7 -> da_fc7 (in-place)
I1015 00:07:34.355304 19737 net.cpp:113] Setting up da_drop7
I1015 00:07:34.355314 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:34.355324 19737 layer_factory.hpp:74] Creating layer da_fc7_da_drop7_0_split
I1015 00:07:34.355334 19737 net.cpp:84] Creating Layer da_fc7_da_drop7_0_split
I1015 00:07:34.355340 19737 net.cpp:380] da_fc7_da_drop7_0_split <- da_fc7
I1015 00:07:34.355348 19737 net.cpp:338] da_fc7_da_drop7_0_split -> da_fc7_da_drop7_0_split_0
I1015 00:07:34.355360 19737 net.cpp:338] da_fc7_da_drop7_0_split -> da_fc7_da_drop7_0_split_1
I1015 00:07:34.355376 19737 net.cpp:113] Setting up da_fc7_da_drop7_0_split
I1015 00:07:34.355386 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:34.355394 19737 net.cpp:120] Top shape: 1 4096 (4096)
I1015 00:07:34.355401 19737 layer_factory.hpp:74] Creating layer cls_score
I1015 00:07:34.355415 19737 net.cpp:84] Creating Layer cls_score
I1015 00:07:34.355424 19737 net.cpp:380] cls_score <- fc7_drop7_0_split_0
I1015 00:07:34.355437 19737 net.cpp:338] cls_score -> cls_score_0
I1015 00:07:34.355448 19737 net.cpp:113] Setting up cls_score
I1015 00:07:34.358413 19737 net.cpp:120] Top shape: 1 20 (20)
I1015 00:07:34.358430 19737 layer_factory.hpp:74] Creating layer da_cls_score
I1015 00:07:34.358441 19737 net.cpp:84] Creating Layer da_cls_score
I1015 00:07:34.358448 19737 net.cpp:380] da_cls_score <- da_fc7_da_drop7_0_split_0
I1015 00:07:34.358461 19737 net.cpp:338] da_cls_score -> cls_score_1
I1015 00:07:34.358474 19737 net.cpp:113] Setting up da_cls_score
I1015 00:07:34.361421 19737 net.cpp:120] Top shape: 1 20 (20)
I1015 00:07:34.361440 19737 layer_factory.hpp:74] Creating layer bbox_pred
I1015 00:07:34.361451 19737 net.cpp:84] Creating Layer bbox_pred
I1015 00:07:34.361462 19737 net.cpp:380] bbox_pred <- fc7_drop7_0_split_1
I1015 00:07:34.361472 19737 net.cpp:338] bbox_pred -> bbox_pred_0
I1015 00:07:34.361482 19737 net.cpp:113] Setting up bbox_pred
I1015 00:07:34.373306 19737 net.cpp:120] Top shape: 1 80 (80)
I1015 00:07:34.373332 19737 layer_factory.hpp:74] Creating layer da_bbox_pred
I1015 00:07:34.373345 19737 net.cpp:84] Creating Layer da_bbox_pred
I1015 00:07:34.373353 19737 net.cpp:380] da_bbox_pred <- da_fc7_da_drop7_0_split_1
I1015 00:07:34.373365 19737 net.cpp:338] da_bbox_pred -> bbox_pred_1
I1015 00:07:34.373378 19737 net.cpp:113] Setting up da_bbox_pred
I1015 00:07:34.385094 19737 net.cpp:120] Top shape: 1 80 (80)
I1015 00:07:34.385113 19737 layer_factory.hpp:74] Creating layer sum
I1015 00:07:34.385130 19737 net.cpp:84] Creating Layer sum
I1015 00:07:34.385139 19737 net.cpp:380] sum <- bbox_pred_0
I1015 00:07:34.385148 19737 net.cpp:380] sum <- bbox_pred_1
I1015 00:07:34.385156 19737 net.cpp:338] sum -> bbox_pred
I1015 00:07:34.385166 19737 net.cpp:113] Setting up sum
I1015 00:07:34.385181 19737 net.cpp:120] Top shape: 1 80 (80)
I1015 00:07:34.385190 19737 layer_factory.hpp:74] Creating layer sum
I1015 00:07:34.385198 19737 net.cpp:84] Creating Layer sum
I1015 00:07:34.385205 19737 net.cpp:380] sum <- cls_score_0
I1015 00:07:34.385212 19737 net.cpp:380] sum <- cls_score_1
I1015 00:07:34.385224 19737 net.cpp:338] sum -> cls_score
I1015 00:07:34.385234 19737 net.cpp:113] Setting up sum
I1015 00:07:34.385247 19737 net.cpp:120] Top shape: 1 20 (20)
I1015 00:07:34.385253 19737 layer_factory.hpp:74] Creating layer cls_prob
I1015 00:07:34.385262 19737 net.cpp:84] Creating Layer cls_prob
I1015 00:07:34.385269 19737 net.cpp:380] cls_prob <- cls_score
I1015 00:07:34.385277 19737 net.cpp:338] cls_prob -> cls_prob
I1015 00:07:34.385287 19737 net.cpp:113] Setting up cls_prob
I1015 00:07:34.385368 19737 net.cpp:120] Top shape: 1 20 (20)
I1015 00:07:34.385381 19737 net.cpp:169] cls_prob does not need backward computation.
I1015 00:07:34.385388 19737 net.cpp:169] sum does not need backward computation.
I1015 00:07:34.385393 19737 net.cpp:169] sum does not need backward computation.
I1015 00:07:34.385399 19737 net.cpp:169] da_bbox_pred does not need backward computation.
I1015 00:07:34.385406 19737 net.cpp:169] bbox_pred does not need backward computation.
I1015 00:07:34.385411 19737 net.cpp:169] da_cls_score does not need backward computation.
I1015 00:07:34.385416 19737 net.cpp:169] cls_score does not need backward computation.
I1015 00:07:34.385421 19737 net.cpp:169] da_fc7_da_drop7_0_split does not need backward computation.
I1015 00:07:34.385427 19737 net.cpp:169] da_drop7 does not need backward computation.
I1015 00:07:34.385433 19737 net.cpp:169] da_relu7 does not need backward computation.
I1015 00:07:34.385438 19737 net.cpp:169] da_fc7 does not need backward computation.
I1015 00:07:34.385444 19737 net.cpp:169] da_drop6 does not need backward computation.
I1015 00:07:34.385449 19737 net.cpp:169] da_relu6 does not need backward computation.
I1015 00:07:34.385455 19737 net.cpp:169] da_fc6 does not need backward computation.
I1015 00:07:34.385462 19737 net.cpp:169] da_roi_pool5 does not need backward computation.
I1015 00:07:34.385468 19737 net.cpp:169] da_relu5 does not need backward computation.
I1015 00:07:34.385473 19737 net.cpp:169] da_conv5 does not need backward computation.
I1015 00:07:34.385478 19737 net.cpp:169] da_relu4 does not need backward computation.
I1015 00:07:34.385484 19737 net.cpp:169] da_conv4 does not need backward computation.
I1015 00:07:34.385489 19737 net.cpp:169] da_relu3 does not need backward computation.
I1015 00:07:34.385495 19737 net.cpp:169] da_conv3 does not need backward computation.
I1015 00:07:34.385501 19737 net.cpp:169] da_norm2 does not need backward computation.
I1015 00:07:34.385506 19737 net.cpp:169] da_pool2 does not need backward computation.
I1015 00:07:34.385512 19737 net.cpp:169] da_relu2 does not need backward computation.
I1015 00:07:34.385519 19737 net.cpp:169] da_conv2 does not need backward computation.
I1015 00:07:34.385524 19737 net.cpp:169] da_norm1 does not need backward computation.
I1015 00:07:34.385529 19737 net.cpp:169] da_pool1 does not need backward computation.
I1015 00:07:34.385535 19737 net.cpp:169] da_relu1 does not need backward computation.
I1015 00:07:34.385541 19737 net.cpp:169] da_conv1 does not need backward computation.
I1015 00:07:34.385547 19737 net.cpp:169] fc7_drop7_0_split does not need backward computation.
I1015 00:07:34.385552 19737 net.cpp:169] drop7 does not need backward computation.
I1015 00:07:34.385560 19737 net.cpp:169] relu7 does not need backward computation.
I1015 00:07:34.385565 19737 net.cpp:169] fc7 does not need backward computation.
I1015 00:07:34.385571 19737 net.cpp:169] drop6 does not need backward computation.
I1015 00:07:34.385576 19737 net.cpp:169] relu6 does not need backward computation.
I1015 00:07:34.385581 19737 net.cpp:169] fc6 does not need backward computation.
I1015 00:07:34.385587 19737 net.cpp:169] roi_pool5 does not need backward computation.
I1015 00:07:34.385593 19737 net.cpp:169] relu5 does not need backward computation.
I1015 00:07:34.385599 19737 net.cpp:169] conv5 does not need backward computation.
I1015 00:07:34.385604 19737 net.cpp:169] relu4 does not need backward computation.
I1015 00:07:34.385610 19737 net.cpp:169] conv4 does not need backward computation.
I1015 00:07:34.385617 19737 net.cpp:169] relu3 does not need backward computation.
I1015 00:07:34.385622 19737 net.cpp:169] conv3 does not need backward computation.
I1015 00:07:34.385627 19737 net.cpp:169] norm2 does not need backward computation.
I1015 00:07:34.385633 19737 net.cpp:169] pool2 does not need backward computation.
I1015 00:07:34.385639 19737 net.cpp:169] relu2 does not need backward computation.
I1015 00:07:34.385644 19737 net.cpp:169] conv2 does not need backward computation.
I1015 00:07:34.385650 19737 net.cpp:169] norm1 does not need backward computation.
I1015 00:07:34.385656 19737 net.cpp:169] pool1 does not need backward computation.
I1015 00:07:34.385663 19737 net.cpp:169] relu1 does not need backward computation.
I1015 00:07:34.385668 19737 net.cpp:169] conv1 does not need backward computation.
I1015 00:07:34.385673 19737 net.cpp:169] rois_input_2_split does not need backward computation.
I1015 00:07:34.385679 19737 net.cpp:205] This network produces output bbox_pred
I1015 00:07:34.385685 19737 net.cpp:205] This network produces output cls_prob
I1015 00:07:34.385723 19737 net.cpp:447] Collecting Learning Rate and Weight Decay.
I1015 00:07:34.385738 19737 net.cpp:217] Network initialization done.
I1015 00:07:34.385746 19737 net.cpp:218] Memory required for data: 14463528
nyud2_images+hha_2015_test ss roidb loaded from /data/gpuuser1/fast-rcnn/data/cache/nyud2_images+hha_2015_test_mcg_roidb.pkl
im_detect: 1/654 0.628s 0.007s
im_detect: 2/654 0.553s 0.007s
im_detect: 3/654 0.543s 0.006s
im_detect: 4/654 0.544s 0.006s
im_detect: 5/654 0.531s 0.006s
im_detect: 6/654 0.527s 0.006s
im_detect: 7/654 0.525s 0.006s
im_detect: 8/654 0.519s 0.006s
im_detect: 9/654 0.518s 0.006s
im_detect: 10/654 0.518s 0.006s
im_detect: 11/654 0.518s 0.006s
im_detect: 12/654 0.517s 0.006s
im_detect: 13/654 0.516s 0.006s
im_detect: 14/654 0.515s 0.006s
im_detect: 15/654 0.511s 0.006s
im_detect: 16/654 0.511s 0.006s
im_detect: 17/654 0.511s 0.006s
im_detect: 18/654 0.511s 0.006s
im_detect: 19/654 0.509s 0.006s
im_detect: 20/654 0.510s 0.006s
im_detect: 21/654 0.510s 0.006s
im_detect: 22/654 0.510s 0.006s
im_detect: 23/654 0.508s 0.006s
im_detect: 24/654 0.507s 0.006s
im_detect: 25/654 0.506s 0.006s
im_detect: 26/654 0.505s 0.006s
im_detect: 27/654 0.504s 0.006s
im_detect: 28/654 0.503s 0.006s
im_detect: 29/654 0.502s 0.006s
im_detect: 30/654 0.501s 0.006s
im_detect: 31/654 0.502s 0.006s
im_detect: 32/654 0.502s 0.006s
im_detect: 33/654 0.502s 0.006s
im_detect: 34/654 0.502s 0.006s
im_detect: 35/654 0.501s 0.006s
im_detect: 36/654 0.501s 0.006s
im_detect: 37/654 0.501s 0.006s
im_detect: 38/654 0.500s 0.006s
im_detect: 39/654 0.500s 0.006s
im_detect: 40/654 0.501s 0.006s
im_detect: 41/654 0.501s 0.006s
im_detect: 42/654 0.501s 0.006s
im_detect: 43/654 0.502s 0.006s
im_detect: 44/654 0.502s 0.006s
im_detect: 45/654 0.502s 0.006s
im_detect: 46/654 0.502s 0.006s
im_detect: 47/654 0.502s 0.006s
im_detect: 48/654 0.503s 0.006s
im_detect: 49/654 0.503s 0.006s
im_detect: 50/654 0.503s 0.006s
im_detect: 51/654 0.503s 0.006s
im_detect: 52/654 0.503s 0.006s
im_detect: 53/654 0.503s 0.006s
im_detect: 54/654 0.503s 0.006s
im_detect: 55/654 0.502s 0.006s
im_detect: 56/654 0.502s 0.006s
im_detect: 57/654 0.502s 0.006s
im_detect: 58/654 0.502s 0.006s
im_detect: 59/654 0.502s 0.006s
im_detect: 60/654 0.502s 0.006s
im_detect: 61/654 0.502s 0.006s
im_detect: 62/654 0.502s 0.006s
im_detect: 63/654 0.501s 0.006s
im_detect: 64/654 0.500s 0.006s
im_detect: 65/654 0.500s 0.006s
im_detect: 66/654 0.500s 0.006s
im_detect: 67/654 0.500s 0.006s
im_detect: 68/654 0.500s 0.006s
im_detect: 69/654 0.501s 0.006s
im_detect: 70/654 0.501s 0.006s
im_detect: 71/654 0.500s 0.006s
im_detect: 72/654 0.501s 0.006s
im_detect: 73/654 0.501s 0.006s
im_detect: 74/654 0.501s 0.006s
im_detect: 75/654 0.500s 0.006s
im_detect: 76/654 0.499s 0.006s
im_detect: 77/654 0.499s 0.006s
im_detect: 78/654 0.499s 0.006s
im_detect: 79/654 0.500s 0.006s
im_detect: 80/654 0.499s 0.006s
im_detect: 81/654 0.499s 0.006s
im_detect: 82/654 0.499s 0.006s
im_detect: 83/654 0.499s 0.006s
im_detect: 84/654 0.499s 0.006s
im_detect: 85/654 0.498s 0.006s
im_detect: 86/654 0.498s 0.006s
im_detect: 87/654 0.497s 0.006s
im_detect: 88/654 0.498s 0.006s
im_detect: 89/654 0.497s 0.006s
im_detect: 90/654 0.498s 0.006s
im_detect: 91/654 0.498s 0.006s
im_detect: 92/654 0.498s 0.006s
im_detect: 93/654 0.498s 0.006s
im_detect: 94/654 0.498s 0.006s
im_detect: 95/654 0.498s 0.006s
im_detect: 96/654 0.498s 0.006s
im_detect: 97/654 0.498s 0.006s
im_detect: 98/654 0.498s 0.006s
im_detect: 99/654 0.498s 0.006s
im_detect: 100/654 0.498s 0.006s
im_detect: 101/654 0.498s 0.006s
im_detect: 102/654 0.498s 0.006s
im_detect: 103/654 0.498s 0.006s
im_detect: 104/654 0.498s 0.006s
im_detect: 105/654 0.498s 0.006s
im_detect: 106/654 0.498s 0.006s
im_detect: 107/654 0.499s 0.006s
im_detect: 108/654 0.499s 0.006s
im_detect: 109/654 0.499s 0.006s
im_detect: 110/654 0.499s 0.006s
im_detect: 111/654 0.500s 0.006s
im_detect: 112/654 0.500s 0.006s
im_detect: 113/654 0.500s 0.006s
im_detect: 114/654 0.500s 0.006s
im_detect: 115/654 0.500s 0.006s
im_detect: 116/654 0.501s 0.006s
im_detect: 117/654 0.501s 0.006s
im_detect: 118/654 0.501s 0.006s
im_detect: 119/654 0.501s 0.006s
im_detect: 120/654 0.502s 0.006s
im_detect: 121/654 0.502s 0.006s
im_detect: 122/654 0.502s 0.006s
im_detect: 123/654 0.502s 0.006s
im_detect: 124/654 0.502s 0.006s
im_detect: 125/654 0.502s 0.006s
im_detect: 126/654 0.503s 0.006s
im_detect: 127/654 0.503s 0.006s
im_detect: 128/654 0.503s 0.006s
im_detect: 129/654 0.503s 0.006s
im_detect: 130/654 0.504s 0.006s
im_detect: 131/654 0.504s 0.006s
im_detect: 132/654 0.504s 0.006s
im_detect: 133/654 0.504s 0.006s
im_detect: 134/654 0.504s 0.006s
im_detect: 135/654 0.505s 0.006s
im_detect: 136/654 0.505s 0.006s
im_detect: 137/654 0.505s 0.006s
im_detect: 138/654 0.506s 0.006s
im_detect: 139/654 0.506s 0.006s
im_detect: 140/654 0.506s 0.006s
im_detect: 141/654 0.506s 0.006s
im_detect: 142/654 0.506s 0.006s
im_detect: 143/654 0.507s 0.006s
im_detect: 144/654 0.507s 0.006s
im_detect: 145/654 0.507s 0.006s
im_detect: 146/654 0.508s 0.006s
im_detect: 147/654 0.508s 0.006s
im_detect: 148/654 0.508s 0.006s
im_detect: 149/654 0.508s 0.006s
im_detect: 150/654 0.508s 0.006s
im_detect: 151/654 0.509s 0.006s
im_detect: 152/654 0.509s 0.006s
im_detect: 153/654 0.509s 0.006s
im_detect: 154/654 0.509s 0.006s
im_detect: 155/654 0.509s 0.006s
im_detect: 156/654 0.509s 0.006s
im_detect: 157/654 0.510s 0.006s
im_detect: 158/654 0.510s 0.006s
im_detect: 159/654 0.510s 0.006s
im_detect: 160/654 0.511s 0.006s
im_detect: 161/654 0.511s 0.006s
im_detect: 162/654 0.511s 0.006s
im_detect: 163/654 0.512s 0.006s
im_detect: 164/654 0.512s 0.006s
im_detect: 165/654 0.512s 0.006s
im_detect: 166/654 0.512s 0.006s
im_detect: 167/654 0.513s 0.006s
im_detect: 168/654 0.513s 0.006s
im_detect: 169/654 0.513s 0.006s
im_detect: 170/654 0.513s 0.006s
im_detect: 171/654 0.514s 0.006s
im_detect: 172/654 0.514s 0.006s
im_detect: 173/654 0.514s 0.006s
im_detect: 174/654 0.514s 0.006s
im_detect: 175/654 0.514s 0.006s
im_detect: 176/654 0.514s 0.006s
im_detect: 177/654 0.514s 0.006s
im_detect: 178/654 0.514s 0.006s
im_detect: 179/654 0.514s 0.006s
im_detect: 180/654 0.514s 0.006s
im_detect: 181/654 0.515s 0.006s
im_detect: 182/654 0.515s 0.006s
im_detect: 183/654 0.515s 0.006s
im_detect: 184/654 0.516s 0.006s
im_detect: 185/654 0.516s 0.006s
im_detect: 186/654 0.516s 0.006s
im_detect: 187/654 0.516s 0.006s
im_detect: 188/654 0.516s 0.006s
im_detect: 189/654 0.516s 0.006s
im_detect: 190/654 0.517s 0.006s
im_detect: 191/654 0.517s 0.006s
im_detect: 192/654 0.517s 0.006s
im_detect: 193/654 0.517s 0.006s
im_detect: 194/654 0.517s 0.006s
im_detect: 195/654 0.517s 0.006s
im_detect: 196/654 0.518s 0.006s
im_detect: 197/654 0.518s 0.006s
im_detect: 198/654 0.518s 0.006s
im_detect: 199/654 0.517s 0.006s
im_detect: 200/654 0.517s 0.006s
im_detect: 201/654 0.518s 0.006s
im_detect: 202/654 0.518s 0.006s
im_detect: 203/654 0.518s 0.006s
im_detect: 204/654 0.518s 0.006s
im_detect: 205/654 0.519s 0.006s
im_detect: 206/654 0.519s 0.006s
im_detect: 207/654 0.519s 0.006s
im_detect: 208/654 0.519s 0.006s
im_detect: 209/654 0.519s 0.006s
im_detect: 210/654 0.519s 0.006s
im_detect: 211/654 0.519s 0.006s
im_detect: 212/654 0.519s 0.006s
im_detect: 213/654 0.519s 0.006s
im_detect: 214/654 0.519s 0.006s
im_detect: 215/654 0.519s 0.006s
im_detect: 216/654 0.519s 0.006s
im_detect: 217/654 0.519s 0.006s
im_detect: 218/654 0.519s 0.006s
im_detect: 219/654 0.519s 0.006s
im_detect: 220/654 0.519s 0.006s
im_detect: 221/654 0.519s 0.006s
im_detect: 222/654 0.519s 0.006s
im_detect: 223/654 0.520s 0.006s
im_detect: 224/654 0.520s 0.006s
im_detect: 225/654 0.520s 0.006s
im_detect: 226/654 0.520s 0.006s
im_detect: 227/654 0.520s 0.006s
im_detect: 228/654 0.520s 0.006s
im_detect: 229/654 0.520s 0.006s
im_detect: 230/654 0.521s 0.006s
im_detect: 231/654 0.521s 0.006s
im_detect: 232/654 0.521s 0.006s
im_detect: 233/654 0.521s 0.006s
im_detect: 234/654 0.521s 0.006s
im_detect: 235/654 0.521s 0.006s
im_detect: 236/654 0.521s 0.006s
im_detect: 237/654 0.521s 0.006s
im_detect: 238/654 0.521s 0.006s
im_detect: 239/654 0.522s 0.006s
im_detect: 240/654 0.522s 0.006s
im_detect: 241/654 0.522s 0.006s
im_detect: 242/654 0.522s 0.006s
im_detect: 243/654 0.522s 0.006s
im_detect: 244/654 0.522s 0.006s
im_detect: 245/654 0.522s 0.006s
im_detect: 246/654 0.522s 0.006s
im_detect: 247/654 0.522s 0.006s
im_detect: 248/654 0.522s 0.006s
im_detect: 249/654 0.523s 0.006s
im_detect: 250/654 0.523s 0.006s
im_detect: 251/654 0.523s 0.006s
im_detect: 252/654 0.523s 0.006s
im_detect: 253/654 0.523s 0.006s
im_detect: 254/654 0.523s 0.006s
im_detect: 255/654 0.523s 0.006s
im_detect: 256/654 0.523s 0.006s
im_detect: 257/654 0.524s 0.006s
im_detect: 258/654 0.524s 0.006s
im_detect: 259/654 0.524s 0.006s
im_detect: 260/654 0.524s 0.006s
im_detect: 261/654 0.524s 0.006s
im_detect: 262/654 0.524s 0.006s
im_detect: 263/654 0.524s 0.006s
im_detect: 264/654 0.525s 0.006s
im_detect: 265/654 0.525s 0.006s
im_detect: 266/654 0.525s 0.006s
im_detect: 267/654 0.525s 0.006s
im_detect: 268/654 0.525s 0.006s
im_detect: 269/654 0.525s 0.006s
im_detect: 270/654 0.525s 0.006s
im_detect: 271/654 0.525s 0.006s
im_detect: 272/654 0.525s 0.006s
im_detect: 273/654 0.525s 0.006s
im_detect: 274/654 0.525s 0.006s
im_detect: 275/654 0.525s 0.006s
im_detect: 276/654 0.525s 0.006s
im_detect: 277/654 0.525s 0.006s
im_detect: 278/654 0.525s 0.006s
im_detect: 279/654 0.525s 0.006s
im_detect: 280/654 0.525s 0.006s
im_detect: 281/654 0.525s 0.006s
im_detect: 282/654 0.525s 0.006s
im_detect: 283/654 0.526s 0.006s
im_detect: 284/654 0.526s 0.006s
im_detect: 285/654 0.526s 0.006s
im_detect: 286/654 0.526s 0.006s
im_detect: 287/654 0.526s 0.006s
im_detect: 288/654 0.526s 0.006s
im_detect: 289/654 0.526s 0.006s
im_detect: 290/654 0.526s 0.006s
im_detect: 291/654 0.526s 0.006s
im_detect: 292/654 0.526s 0.006s
im_detect: 293/654 0.526s 0.006s
im_detect: 294/654 0.526s 0.006s
im_detect: 295/654 0.526s 0.006s
im_detect: 296/654 0.526s 0.006s
im_detect: 297/654 0.526s 0.006s
im_detect: 298/654 0.526s 0.006s
im_detect: 299/654 0.526s 0.006s
im_detect: 300/654 0.526s 0.006s
im_detect: 301/654 0.526s 0.006s
im_detect: 302/654 0.526s 0.006s
im_detect: 303/654 0.526s 0.006s
im_detect: 304/654 0.527s 0.006s
im_detect: 305/654 0.527s 0.006s
im_detect: 306/654 0.527s 0.007s
im_detect: 307/654 0.527s 0.007s
im_detect: 308/654 0.527s 0.007s
im_detect: 309/654 0.527s 0.007s
im_detect: 310/654 0.527s 0.007s
im_detect: 311/654 0.527s 0.007s
im_detect: 312/654 0.527s 0.007s
im_detect: 313/654 0.527s 0.007s
im_detect: 314/654 0.527s 0.007s
im_detect: 315/654 0.527s 0.007s
im_detect: 316/654 0.527s 0.007s
im_detect: 317/654 0.527s 0.007s
im_detect: 318/654 0.527s 0.007s
im_detect: 319/654 0.527s 0.007s
im_detect: 320/654 0.527s 0.007s
im_detect: 321/654 0.527s 0.007s
im_detect: 322/654 0.528s 0.007s
im_detect: 323/654 0.528s 0.007s
im_detect: 324/654 0.528s 0.007s
im_detect: 325/654 0.528s 0.007s
im_detect: 326/654 0.528s 0.007s
im_detect: 327/654 0.528s 0.007s
im_detect: 328/654 0.528s 0.007s
im_detect: 329/654 0.528s 0.007s
im_detect: 330/654 0.528s 0.007s
im_detect: 331/654 0.529s 0.007s
im_detect: 332/654 0.529s 0.007s
im_detect: 333/654 0.529s 0.007s
im_detect: 334/654 0.529s 0.007s
im_detect: 335/654 0.529s 0.007s
im_detect: 336/654 0.529s 0.007s
im_detect: 337/654 0.529s 0.007s
im_detect: 338/654 0.529s 0.007s
im_detect: 339/654 0.529s 0.007s
im_detect: 340/654 0.529s 0.007s
im_detect: 341/654 0.529s 0.007s
im_detect: 342/654 0.529s 0.007s
im_detect: 343/654 0.529s 0.007s
im_detect: 344/654 0.530s 0.007s
im_detect: 345/654 0.530s 0.007s
im_detect: 346/654 0.530s 0.007s
im_detect: 347/654 0.530s 0.007s
im_detect: 348/654 0.530s 0.007s
im_detect: 349/654 0.530s 0.007s
im_detect: 350/654 0.530s 0.007s
im_detect: 351/654 0.530s 0.007s
im_detect: 352/654 0.530s 0.007s
im_detect: 353/654 0.530s 0.007s
im_detect: 354/654 0.531s 0.007s
im_detect: 355/654 0.531s 0.007s
im_detect: 356/654 0.531s 0.007s
im_detect: 357/654 0.531s 0.007s
im_detect: 358/654 0.531s 0.007s
im_detect: 359/654 0.531s 0.007s
im_detect: 360/654 0.531s 0.007s
im_detect: 361/654 0.531s 0.007s
im_detect: 362/654 0.531s 0.007s
im_detect: 363/654 0.531s 0.007s
im_detect: 364/654 0.531s 0.007s
im_detect: 365/654 0.532s 0.007s
im_detect: 366/654 0.532s 0.007s
im_detect: 367/654 0.532s 0.007s
im_detect: 368/654 0.532s 0.007s
im_detect: 369/654 0.532s 0.007s
im_detect: 370/654 0.532s 0.007s
im_detect: 371/654 0.532s 0.007s
im_detect: 372/654 0.532s 0.007s
im_detect: 373/654 0.532s 0.007s
im_detect: 374/654 0.532s 0.007s
im_detect: 375/654 0.532s 0.007s
im_detect: 376/654 0.532s 0.007s
im_detect: 377/654 0.532s 0.007s
im_detect: 378/654 0.533s 0.007s
im_detect: 379/654 0.533s 0.007s
im_detect: 380/654 0.533s 0.007s
im_detect: 381/654 0.533s 0.007s
im_detect: 382/654 0.533s 0.007s
im_detect: 383/654 0.533s 0.007s
im_detect: 384/654 0.533s 0.007s
im_detect: 385/654 0.533s 0.007s
im_detect: 386/654 0.533s 0.007s
im_detect: 387/654 0.533s 0.007s
im_detect: 388/654 0.533s 0.007s
im_detect: 389/654 0.533s 0.007s
im_detect: 390/654 0.534s 0.007s
im_detect: 391/654 0.534s 0.007s
im_detect: 392/654 0.534s 0.007s
im_detect: 393/654 0.534s 0.007s
im_detect: 394/654 0.534s 0.007s
im_detect: 395/654 0.534s 0.007s
im_detect: 396/654 0.534s 0.007s
im_detect: 397/654 0.534s 0.007s
im_detect: 398/654 0.534s 0.007s
im_detect: 399/654 0.534s 0.007s
im_detect: 400/654 0.534s 0.007s
im_detect: 401/654 0.534s 0.007s
im_detect: 402/654 0.534s 0.007s
im_detect: 403/654 0.534s 0.007s
im_detect: 404/654 0.535s 0.007s
im_detect: 405/654 0.535s 0.007s
im_detect: 406/654 0.535s 0.007s
im_detect: 407/654 0.535s 0.007s
im_detect: 408/654 0.535s 0.007s
im_detect: 409/654 0.535s 0.007s
im_detect: 410/654 0.535s 0.007s
im_detect: 411/654 0.535s 0.007s
im_detect: 412/654 0.535s 0.007s
im_detect: 413/654 0.535s 0.007s
im_detect: 414/654 0.535s 0.007s
im_detect: 415/654 0.535s 0.007s
im_detect: 416/654 0.535s 0.007s
im_detect: 417/654 0.535s 0.007s
im_detect: 418/654 0.535s 0.007s
im_detect: 419/654 0.535s 0.007s
im_detect: 420/654 0.535s 0.007s
im_detect: 421/654 0.535s 0.007s
im_detect: 422/654 0.535s 0.007s
im_detect: 423/654 0.535s 0.007s
im_detect: 424/654 0.535s 0.007s
im_detect: 425/654 0.535s 0.007s
im_detect: 426/654 0.535s 0.007s
im_detect: 427/654 0.535s 0.007s
im_detect: 428/654 0.536s 0.007s
im_detect: 429/654 0.536s 0.007s
im_detect: 430/654 0.536s 0.007s
im_detect: 431/654 0.536s 0.007s
im_detect: 432/654 0.536s 0.007s
im_detect: 433/654 0.536s 0.007s
im_detect: 434/654 0.536s 0.007s
im_detect: 435/654 0.536s 0.007s
im_detect: 436/654 0.536s 0.007s
im_detect: 437/654 0.536s 0.007s
im_detect: 438/654 0.536s 0.007s
im_detect: 439/654 0.536s 0.007s
im_detect: 440/654 0.536s 0.007s
im_detect: 441/654 0.536s 0.007s
im_detect: 442/654 0.536s 0.007s
im_detect: 443/654 0.536s 0.007s
im_detect: 444/654 0.536s 0.007s
im_detect: 445/654 0.537s 0.007s
im_detect: 446/654 0.536s 0.007s
im_detect: 447/654 0.537s 0.007s
im_detect: 448/654 0.537s 0.007s
im_detect: 449/654 0.537s 0.007s
im_detect: 450/654 0.537s 0.007s
im_detect: 451/654 0.537s 0.007s
im_detect: 452/654 0.537s 0.007s
im_detect: 453/654 0.537s 0.007s
im_detect: 454/654 0.537s 0.007s
im_detect: 455/654 0.537s 0.007s
im_detect: 456/654 0.537s 0.007s
im_detect: 457/654 0.537s 0.007s
im_detect: 458/654 0.537s 0.007s
im_detect: 459/654 0.537s 0.007s
im_detect: 460/654 0.537s 0.007s
im_detect: 461/654 0.537s 0.007s
im_detect: 462/654 0.537s 0.007s
im_detect: 463/654 0.537s 0.007s
im_detect: 464/654 0.537s 0.007s
im_detect: 465/654 0.537s 0.007s
im_detect: 466/654 0.538s 0.007s
im_detect: 467/654 0.538s 0.007s
im_detect: 468/654 0.538s 0.007s
im_detect: 469/654 0.538s 0.007s
im_detect: 470/654 0.538s 0.007s
im_detect: 471/654 0.538s 0.007s
im_detect: 472/654 0.538s 0.007s
im_detect: 473/654 0.538s 0.007s
im_detect: 474/654 0.538s 0.007s
im_detect: 475/654 0.538s 0.007s
im_detect: 476/654 0.538s 0.007s
im_detect: 477/654 0.538s 0.007s
im_detect: 478/654 0.538s 0.007s
im_detect: 479/654 0.538s 0.007s
im_detect: 480/654 0.538s 0.007s
im_detect: 481/654 0.538s 0.007s
im_detect: 482/654 0.538s 0.007s
im_detect: 483/654 0.538s 0.007s
im_detect: 484/654 0.538s 0.007s
im_detect: 485/654 0.538s 0.007s
im_detect: 486/654 0.538s 0.007s
im_detect: 487/654 0.539s 0.007s
im_detect: 488/654 0.539s 0.007s
im_detect: 489/654 0.539s 0.007s
im_detect: 490/654 0.539s 0.007s
im_detect: 491/654 0.539s 0.007s
im_detect: 492/654 0.539s 0.007s
im_detect: 493/654 0.539s 0.007s
im_detect: 494/654 0.539s 0.007s
im_detect: 495/654 0.538s 0.007s
im_detect: 496/654 0.539s 0.007s
im_detect: 497/654 0.539s 0.007s
im_detect: 498/654 0.539s 0.007s
im_detect: 499/654 0.539s 0.007s
im_detect: 500/654 0.539s 0.006s
im_detect: 501/654 0.539s 0.006s
im_detect: 502/654 0.539s 0.006s
im_detect: 503/654 0.539s 0.006s
im_detect: 504/654 0.539s 0.006s
im_detect: 505/654 0.539s 0.006s
im_detect: 506/654 0.539s 0.006s
im_detect: 507/654 0.539s 0.006s
im_detect: 508/654 0.539s 0.006s
im_detect: 509/654 0.539s 0.006s
im_detect: 510/654 0.539s 0.006s
im_detect: 511/654 0.539s 0.006s
im_detect: 512/654 0.539s 0.006s
im_detect: 513/654 0.539s 0.006s
im_detect: 514/654 0.539s 0.006s
im_detect: 515/654 0.539s 0.006s
im_detect: 516/654 0.539s 0.006s
im_detect: 517/654 0.539s 0.006s
im_detect: 518/654 0.539s 0.006s
im_detect: 519/654 0.539s 0.006s
im_detect: 520/654 0.539s 0.006s
im_detect: 521/654 0.539s 0.006s
im_detect: 522/654 0.539s 0.006s
im_detect: 523/654 0.539s 0.006s
im_detect: 524/654 0.539s 0.006s
im_detect: 525/654 0.539s 0.006s
im_detect: 526/654 0.539s 0.006s
im_detect: 527/654 0.539s 0.006s
im_detect: 528/654 0.539s 0.006s
im_detect: 529/654 0.539s 0.006s
im_detect: 530/654 0.539s 0.006s
im_detect: 531/654 0.540s 0.006s
im_detect: 532/654 0.540s 0.006s
im_detect: 533/654 0.540s 0.006s
im_detect: 534/654 0.540s 0.006s
im_detect: 535/654 0.540s 0.006s
im_detect: 536/654 0.540s 0.006s
im_detect: 537/654 0.540s 0.006s
im_detect: 538/654 0.540s 0.006s
im_detect: 539/654 0.540s 0.006s
im_detect: 540/654 0.540s 0.006s
im_detect: 541/654 0.540s 0.006s
im_detect: 542/654 0.540s 0.006s
im_detect: 543/654 0.540s 0.006s
im_detect: 544/654 0.540s 0.006s
im_detect: 545/654 0.540s 0.006s
im_detect: 546/654 0.540s 0.006s
im_detect: 547/654 0.540s 0.006s
im_detect: 548/654 0.540s 0.006s
im_detect: 549/654 0.540s 0.006s
im_detect: 550/654 0.540s 0.006s
im_detect: 551/654 0.541s 0.006s
im_detect: 552/654 0.541s 0.006s
im_detect: 553/654 0.541s 0.006s
im_detect: 554/654 0.541s 0.006s
im_detect: 555/654 0.541s 0.006s
im_detect: 556/654 0.541s 0.006s
im_detect: 557/654 0.541s 0.006s
im_detect: 558/654 0.541s 0.006s
im_detect: 559/654 0.541s 0.006s
im_detect: 560/654 0.541s 0.006s
im_detect: 561/654 0.541s 0.006s
im_detect: 562/654 0.541s 0.006s
im_detect: 563/654 0.541s 0.006s
im_detect: 564/654 0.541s 0.006s
im_detect: 565/654 0.541s 0.006s
im_detect: 566/654 0.541s 0.006s
im_detect: 567/654 0.541s 0.006s
im_detect: 568/654 0.541s 0.006s
im_detect: 569/654 0.541s 0.006s
im_detect: 570/654 0.541s 0.006s
im_detect: 571/654 0.541s 0.006s
im_detect: 572/654 0.542s 0.006s
im_detect: 573/654 0.542s 0.006s
im_detect: 574/654 0.542s 0.006s
im_detect: 575/654 0.542s 0.006s
im_detect: 576/654 0.542s 0.006s
im_detect: 577/654 0.542s 0.006s
im_detect: 578/654 0.542s 0.006s
im_detect: 579/654 0.542s 0.006s
im_detect: 580/654 0.542s 0.006s
im_detect: 581/654 0.542s 0.006s
im_detect: 582/654 0.542s 0.006s
im_detect: 583/654 0.542s 0.006s
im_detect: 584/654 0.542s 0.006s
im_detect: 585/654 0.542s 0.006s
im_detect: 586/654 0.542s 0.006s
im_detect: 587/654 0.542s 0.006s
im_detect: 588/654 0.542s 0.006s
im_detect: 589/654 0.542s 0.006s
im_detect: 590/654 0.542s 0.006s
im_detect: 591/654 0.542s 0.006s
im_detect: 592/654 0.542s 0.006s
im_detect: 593/654 0.542s 0.006s
im_detect: 594/654 0.542s 0.006s
im_detect: 595/654 0.543s 0.006s
im_detect: 596/654 0.542s 0.006s
im_detect: 597/654 0.543s 0.006s
im_detect: 598/654 0.543s 0.006s
im_detect: 599/654 0.543s 0.006s
im_detect: 600/654 0.543s 0.006s
im_detect: 601/654 0.543s 0.006s
im_detect: 602/654 0.543s 0.006s
im_detect: 603/654 0.543s 0.006s
im_detect: 604/654 0.543s 0.006s
im_detect: 605/654 0.543s 0.006s
im_detect: 606/654 0.543s 0.006s
im_detect: 607/654 0.543s 0.006s
im_detect: 608/654 0.543s 0.006s
im_detect: 609/654 0.543s 0.006s
im_detect: 610/654 0.543s 0.006s
im_detect: 611/654 0.543s 0.006s
im_detect: 612/654 0.543s 0.006s
im_detect: 613/654 0.543s 0.006s
im_detect: 614/654 0.543s 0.006s
im_detect: 615/654 0.543s 0.006s
im_detect: 616/654 0.543s 0.006s
im_detect: 617/654 0.543s 0.006s
im_detect: 618/654 0.543s 0.006s
im_detect: 619/654 0.543s 0.006s
im_detect: 620/654 0.543s 0.006s
im_detect: 621/654 0.544s 0.006s
im_detect: 622/654 0.544s 0.006s
im_detect: 623/654 0.544s 0.006s
im_detect: 624/654 0.544s 0.006s
im_detect: 625/654 0.544s 0.006s
im_detect: 626/654 0.544s 0.006s
im_detect: 627/654 0.544s 0.006s
im_detect: 628/654 0.544s 0.006s
im_detect: 629/654 0.544s 0.006s
im_detect: 630/654 0.544s 0.006s
im_detect: 631/654 0.544s 0.006s
im_detect: 632/654 0.544s 0.006s
im_detect: 633/654 0.544s 0.006s
im_detect: 634/654 0.544s 0.006s
im_detect: 635/654 0.544s 0.006s
im_detect: 636/654 0.544s 0.006s
im_detect: 637/654 0.544s 0.006s
im_detect: 638/654 0.544s 0.006s
im_detect: 639/654 0.544s 0.006s
im_detect: 640/654 0.544s 0.006s
im_detect: 641/654 0.544s 0.006s
im_detect: 642/654 0.544s 0.006s
im_detect: 643/654 0.544s 0.006s
im_detect: 644/654 0.544s 0.006s
im_detect: 645/654 0.544s 0.006s
im_detect: 646/654 0.544s 0.006s
im_detect: 647/654 0.544s 0.006s
im_detect: 648/654 0.544s 0.006s
im_detect: 649/654 0.544s 0.006s
im_detect: 650/654 0.544s 0.006s
im_detect: 651/654 0.545s 0.006s
im_detect: 652/654 0.545s 0.006s
im_detect: 653/654 0.545s 0.006s
im_detect: 654/654 0.545s 0.006s
Applying NMS to all detections
Evaluating detections
nyud2_images+hha_2015_test gt roidb loaded from /data/gpuuser1/fast-rcnn/data/cache/nyud2_images+hha_2015_test_gt_roidb.pkl
bathtub             : 41.373769
bed                 : 76.322862
bookshelf           : 46.013688
box                 :  1.903583
chair               : 50.638787
counter             : 51.719871
desk                : 19.546341
door                : 26.033469
dresser             : 55.784730
garbage-bin         : 37.603302
lamp                : 40.578655
monitor             : 60.070577
night-stand         : 55.383287
pillow              : 44.794861
sink                : 44.877141
sofa                : 64.095214
table               : 30.473090
television          : 50.450144
toilet              : 62.468012
mean                : 45.270073
